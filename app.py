import os
import time
import http.client
import streamlit as st
import speech_recognition as sr
from pydub import AudioSegment, silence

# --- –ï—Å–ª–∏ –Ω—É–∂–µ–Ω –æ—Ñ–ª–∞–π–Ω-—Ä–µ–∂–∏–º ---
try:
    from vosk import Model, KaldiRecognizer
    import wave
    import json
    VOSK_AVAILABLE = True
except ImportError:
    VOSK_AVAILABLE = False

# ======== –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ========
VOSK_MODEL_PATH = "vosk-model-ru"  # –ø–∞–ø–∫–∞ —Å –º–æ–¥–µ–ª—å—é Vosk
MAX_RETRIES = 3  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–µ API
# ===========================

def convert_to_wav(input_path):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –ª—é–±–æ–π –∞—É–¥–∏–æ—Ñ–∞–π–ª –≤ WAV (16kHz, mono)"""
    audio = AudioSegment.from_file(input_path)
    wav_path = os.path.splitext(input_path)[0] + "_converted.wav"
    audio = audio.set_frame_rate(16000).set_channels(1)
    audio.export(wav_path, format="wav")
    return wav_path


def transcribe_large_file_on_silence(input_path, use_offline=False):
    """
    –†–∞—Å–ø–æ–∑–Ω–∞—ë—Ç –¥–ª–∏–Ω–Ω–æ–µ –∞—É–¥–∏–æ, —Ä–µ–∂–µ—Ç –ø–æ —Ç–∏—à–∏–Ω–µ, –¥–µ–ª–∞–µ—Ç –ø–æ–≤—Ç–æ—Ä –∑–∞–ø—Ä–æ—Å–∞ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö.
    """
    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ WAV –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    if not input_path.lower().endswith(".wav"):
        input_path = convert_to_wav(input_path)

    audio = AudioSegment.from_wav(input_path)
    chunks = silence.split_on_silence(
        audio,
        min_silence_len=500,
        silence_thresh=-40,
        keep_silence=300
    )

    result_text = ""

    if use_offline:
        if not VOSK_AVAILABLE:
            st.error("Vosk –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü–æ—Å—Ç–∞–≤—å—Ç–µ –ø–∞–∫–µ—Ç vosk –¥–ª—è –æ—Ñ–ª–∞–π–Ω-—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è.")
            return ""
        if not os.path.exists(VOSK_MODEL_PATH):
            st.error(f"–ú–æ–¥–µ–ª—å Vosk –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ –ø—É—Ç–∏ {VOSK_MODEL_PATH}")
            return ""

        model = Model(VOSK_MODEL_PATH)

        for i, chunk in enumerate(chunks):
            chunk_path = f"chunk_{i}.wav"
            chunk.export(chunk_path, format="wav")

            wf = wave.open(chunk_path, "rb")
            rec = KaldiRecognizer(model, wf.getframerate())

            while True:
                data = wf.readframes(4000)
                if not data:
                    break
                if rec.AcceptWaveform(data):
                    result_text += json.loads(rec.Result())["text"] + " "
            result_text += json.loads(rec.FinalResult())["text"] + " "

            wf.close()
            os.remove(chunk_path)

    else:
        recognizer = sr.Recognizer()

        for i, chunk in enumerate(chunks):
            chunk_path = f"chunk_{i}.wav"
            chunk.export(chunk_path, format="wav")

            with sr.AudioFile(chunk_path) as source:
                audio_data = recognizer.record(source)

                attempt = 0
                while attempt < MAX_RETRIES:
                    try:
                        text = recognizer.recognize_google(audio_data, language="ru-RU")
                        result_text += text + " "
                        break
                    except sr.UnknownValueError:
                        break
                    except (sr.RequestError, http.client.IncompleteRead) as e:
                        attempt += 1
                        time.sleep(1)

            os.remove(chunk_path)

    return result_text.strip()


# ========== Streamlit UI ==========
st.title("üéô –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç")
st.write("–ó–∞–≥—Ä—É–∑–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª (MP3, WAV, M4A, OGG) –∏ –ø–æ–ª—É—á–∏ —Ç–µ–∫—Å—Ç.")

use_offline = st.checkbox("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Ñ–ª–∞–π–Ω-—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ (Vosk)", value=False)

uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª", type=["mp3", "wav", "m4a", "ogg"])

if uploaded_file is not None:
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    input_path = os.path.join("temp_audio", uploaded_file.name)
    os.makedirs("temp_audio", exist_ok=True)
    with open(input_path, "wb") as f:
        f.write(uploaded_file.read())

    st.write("‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞...")
    text_result = transcribe_large_file_on_silence(input_path, use_offline=use_offline)

    if text_result:
        st.success("‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        st.text_area("–†–µ–∑—É–ª—å—Ç–∞—Ç", text_result, height=300)
        st.download_button("üíæ –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç", text_result, file_name="transcription.txt")

    # –ß–∏—Å—Ç–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    os.remove(input_path)
